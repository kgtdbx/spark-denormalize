## a data source which is accessed through JDBC
##
kind: JDBCDataSource

## the metadata of this resource
##
metadata:

  ## the name of this data source
  ##
  name: ""

## the spec of this resource
##
spec:

  ## the JDBC connection string
  ##
  ## EXAMPLE:
  ##    connection: "jdbc:informix-sqli://..."
  ##
  connection: ""

  ## the JDBC driver class to use
  ##
  ## NOTE:
  ##  - must be provided in `Config().spec.spark.packages` or `Config().spec.spark.jars`
  ##
  ## EXAMPLE:
  ##    driverClass: "com.informix.jdbc.IfxDriver"
  ##
  driverClass: ""

  ## a reference to a table
  ##
  ## NOTE:
  ##  - this is database-flavor specific
  ##
  ## EXAMPLE:
  ##    tableReference: "my_db.my_table"
  ##
  tableReference: ""

  ## a list of table predicates (used for read parallelism)
  ##
  ## WARNING:
  ##  - these filters should not overlap, otherwise rows will be duplicated
  ##  - these filters should cover ALL rows in the table, otherwise some rows will be missed
  ##
  ## EXAMPLE -- split on numeric ID column:
  ##    tablePredicates:
  ##      - "mod(my_part_col, 3) = 0"
  ##      - "mod(my_part_col, 3) = 1"
  ##      - "mod(my_part_col, 3) = 2"
  ##      - "mod(my_part_col, 3) = 3"
  ##
  tablePredicates: []

  ## configs describing how snapshots are stored
  ##
  snapshotConfig:

    ## the fields containing the snapshot time
    ##
    ## NOTE:
    ##  - if {} is provided, we assume the data corresponds to the read-time
    ##    (which is the case if this data-source is the production system)
    ##
    existingField:

      ## the name of a field
      ##
      ## NOTE:
      ##  - if this field is created by `sourceUriPrefix` extraction, we extract snapshot values based
      ##    off the URI-path directly, (reducing the number of HDFS/S3/GCS API calls)
      ##
      name: ""

      ## the format the snapshot is stored in
      ##
      ## FORMAT:
      ##  - `TIMESTAMP`:          a timestamp type
      ##  - `UNIX_SECONDS`:       a integer with unix epoch in seconds
      ##  - `UNIX_MILLISECONDS`:  a long with unix epoch in milliseconds
      ##  - *`ISO8601_DATE_TIME`: a string with ISO8601 date-time format (ex: '2020-01-01T00:00:00Z')
      ##  - **`ISO8601_DATE`:     a string with ISO8601 date format (ex: '2020-01-01')
      ##
      ## *  = `defaultTimezone` is used (if missing from string)
      ## ** = read as midnight in the `defaultTimezone`
      ##
      format: ""

      ## the default timezone
      ##
      ## NOTE:
      ##  - currently only applicable to: `ISO8601_DATE_TIME`, `ISO8601_DATE`
      ##
      defaultTimezone: "UTC"

  ## manual schema specification
  ##
  ## WARNING:
  ##  - if the schema is incompatible with the data, the data reading will fail
  ##
  ## NOTE:
  ##  - this is OPTIONAL (but could be specified for validation or adding metadata)
  ##
  ## FORMAT:
  ##  - similar to the spark format (but in YAML syntax)
  ##    https://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/types/DataType$.html
  ##
  schemaFields:

    - ## metadata tags to apply to this field
      ##
      metadata: {}

      ## the name of the field
      ##
      name: ""

      ## if this field can contain nulls
      ##
      ## WARNING:
      ##  - setting `false` will cause the job to fail if null is encountered
      ##
      nullable: true

      ## the type of the field
      ##
      ## FORMAT:
      ##  - `array`
      ##  - `binary`
      ##  - `boolean`
      ##  - `byte`
      ##  - `date`
      ##  - `decimal(<precision>,<scale>)`
      ##  - `double`
      ##  - `float`
      ##  - `integer`
      ##  - `long`
      ##  - `map`
      ##  - `null`
      ##  - `short`
      ##  - `string`
      ##  - `struct`
      ##  - `timestamp`
      ##
      type: ""

      ## for `type=struct` || the fields inside the struct
      ##
      ## NOTE:
      ##  - the elements of this list are formatted the same as `schemaFields`
      ##
      fields: []

      ## for `type=array` || the type contained inside the array
      ##
      ## NOTE:
      ##  - if "": must be the name of a basic data type
      ##  - if {}: must must be formatted like `schemaFields`
      ##
      elementType: "" or {}

      ## for `type=array` ||  if the array can contain NULL values
      ##
      containsNull: false

      ## for `type=map` || the type of the mapping key
      ##
      ## NOTE:
      ##  - if "": must be the name of a basic data type
      ##  - if {}: must must be formatted like `schemaFields`
      ##
      keyType: "" or {}

      ## for `type=map` || the type of the mapping value
      ##
      ## NOTE:
      ##  - if "": must be the name of a basic data type
      ##  - if {}: must must be formatted like `schemaFields`
      ##
      valueType: "" or {}

      ## for `type=map` ||  if the mapping value can contain NULL values
      ##
      valueContainsNull: false

  ## a list of metadata applicators to apply
  ##
  ## NOTE:
  ##  - metadata applicators are applied IN ORDER
  ##
  metadataApplicators:

    - ## the name of a MetadataApplicator resource
      ##
      name: ""