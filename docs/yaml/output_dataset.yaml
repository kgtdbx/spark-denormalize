## the resource api version
##
apiVersion: v1

## an output dataset which combines data sources
##
kind: OutputDataset

## the metadata of this resource
##
metadata:

  ## the name of this output dataset
  ##
  name: "test" ## TODO: remove after test

## the spec of this resource
##
spec:

  ## configs related to the data model
  ##
  dataModel:

    ## the root data source of the data model tree
    ##
    rootDataSource:

      ## the data source
      ##
      dataSource:

        ## the kind of data source
        ##
        kind: "HDFSLikeDataSource" ## TODO: remove after test

        ## the name of the data source
        ##
        name: "test" ## TODO: remove after test

      ## configs describing which snapshots to include
      ##
      snapshotFilter:

        ## where we split time into intervals, and include a single snapshot from each
        ##
        fromInterval:

          ## which snapshot to prefer when multiple are valid
          ##
          ## FORMAT:
          ##  - `NEWEST`: prefer the newest valid snapshot
          ##  - `OLDEST`: prefer the oldest valid snapshot
          ##
          preference: "NEWEST"

          ## the start of the first interval
          ##
          ## WARNING:
          ##  - all time components must be specified
          ##
          ## NOTE:
          ##  - snapshots before this time will NOT be included
          ##
          intervalStartDate:

            ## the year
            ##
            year: 2020

            ## the month-of-year, from 1 (January) to 12 (December)
            ##
            month: 1

            ## the day-of-month, from 1 to 31
            ##
            day: 1

            ## the hour-of-day, from 0 to 23
            ##
            hour: 0

            ## the minute-of-hour, from 0 to 59
            ##
            minute: 0

            ## the second-of-minute, from 0 to 59
            ##
            second: 0

            ## the nano-of-second, from 0 to 999,999,999
            ##
            nano: 0

            ## the time-zone ("tz database" format)
            ##
            ## EXAMPLE:
            ##    timezone: "America/New_York"
            ##
            timezone: "UTC"

          ## the length of the interval
          ##
          ## NOTE:
          ##  - timezone aware
          ##  - behaves in the same way as `java.time.ZonedDateTime`: `plusYears()`, `plusDays()`, ...
          ##
          intervalLength:
            nano: 0
            second: 0
            minute: 0
            hour: 0
            day: 0
            week: 0
            month: 0
            year: 0

    ## the list of other data sources in the data model tree
    ##
    otherDataSources:

      - ## the data source
        ##
        dataSource:

          ## the kind of data source
          ##
          kind: "JDBCDataSource" ## TODO: remove after test

          ## the name of the data source
          ##
          name: "test" ## TODO: remove after test

        ## the fields from this data source be will collected into a STRUCT field having this name
        ##
        ## WARNING:
        ##  - must must be unique within this OutputDataset
        ##
        fieldName: "test" ## TODO: remove after test

        ## the behaviour if this DataSource has no path to the root data source
        ##
        ## FORMAT:
        ##  - `ERROR`:           fail the job
        ##  - `CONTINUE_IGNORE`: ignore silently, not including this data source in the data model
        ##  - `CONTINUE_WARN`:   emit warning, not including this data source in the data model
        ##
        pathMissingMode: "ERROR"

        ## the behaviour if a required join field is missing from this data source, or its graph parent (for a given root snapshot)
        ##
        ## FORMAT:
        ##  - `ERROR`:           fail the job
        ##  - `CONTINUE_IGNORE`: ignore silently, exclude this data source and its graph children, for a specific snapshot
        ##  - `CONTINUE_WARN`:   emit warning, exclude this data source and its graph children, for a specific snapshot
        ##  - `SKIP_IGNORE`:     ignore silently, skip this root snapshot
        ##  - `SKIP_WARN`:       emit warning, skip this root snapshot
        ##
        joinFieldMissingMode: "ERROR"

        ## optional data transformations to apply to this data source
        ##
        transformations:

          ## a transformation which groups the data into an `ARRAY<STRUCT>`
          ##
          ## WARNING:
          ##  - this config cannot change after the first run
          ##
          ## NOTE:
          ##  - this transformation is provided to account for data sources which
          ##    have a one-to-many relationship to the root data source
          ##  - this will cause all data which is joined to the root through this source to be grouped as well
          ##
          groupBy:

            ## the list of field names to group-by
            ##
            ## WARNING:
            ##  - if multiple field names are defined, they will act as a compound key (order matters)
            ##  - only this field (or compound field) will be considered for relationship join keys,
            ##    because other fields are not guaranteed to be consistent inside the array
            ##
            fieldNames: []

            ## the behaviour if a required group field is missing from this data source (for a given root snapshot)
            ##
            ## FORMAT:
            ##  - `ERROR`:           fail the job
            ##  - `CONTINUE_IGNORE`: ignore silently, exclude this data source and its graph children, for a specific snapshot
            ##  - `CONTINUE_WARN`:   emit warning, exclude this data source and its graph children, for a specific snapshot
            ##  - `SKIP_IGNORE`:     ignore silently, skip this root snapshot
            ##  - `SKIP_WARN`:       emit warning, skip this root snapshot
            ##
            groupByFieldMissingMode: "ERROR"

        ## configs relating to snapshots of this data source
        ##
        snapshot:

          ## the snapshot to prefer if multiple are valid
          ##
          ## FORMAT:
          ##  - `NEWEST`: prefer the newest valid snapshot
          ##  - `OLDEST`: prefer the oldest valid snapshot
          ##
          preference: "NEWEST"

          ## the behaviour if there is no valid snapshot of this data source (for a given root snapshot)
          ##
          ## FORMAT:
          ##  - `ERROR`:           fail the job
          ##  - `CONTINUE_IGNORE`: ignore silently, exclude this data source and its graph children, for a specific snapshot
          ##  - `CONTINUE_WARN`:   emit warning, exclude this data source and its graph children, for a specific snapshot
          ##  - `SKIP_IGNORE`:     ignore silently, skip this root snapshot
          ##  - `SKIP_WARN`:       emit warning, skip this root snapshot
          ##
          snapshotMissingMode: "ERROR"

          ## the maximum time BEFORE the root snapshot
          ##
          ## NOTE:
          ##  - timezone aware
          ##  - behaves in the same way as `java.time.ZonedDateTime`: `plusYears()`, `plusDays()`, ...
          ##
          timeBefore:
            nano: 0
            second: 0
            minute: 0
            hour: 0
            day: 0
            week: 0
            month: 0
            year: 0

          ## the maximum time AFTER the root snapshot
          ##
          ## NOTE:
          ##  - timezone aware
          ##  - behaves in the same way as `java.time.ZonedDateTime`: `plusYears()`, `plusDays()`, ...
          ##
          timeAfter:
            nano: 0
            second: 0
            minute: 0
            hour: 0
            day: 0
            week: 0
            month: 0
            year: 0

    ## the list of data relationships in the data model tree
    ##
    dataRelationships:

      - ## the name of the data relationship
        ##
        name: "test" ## TODO: remove after test

        ## used to multiple minimum-spanning-tree of the relationship graph
        ##
        ## WARNING:
        ##  - this must be a positive whole number
        ##
        ## NOTE:
        ##  - the minimum-spanning-trees are always calculated on the unweighted graph,
        ##    and if multiple are returned, we use `antiPriority` choose one
        ##    (that is to say, the number of joins is always considered first,
        ##    and `antiPriority` is used to distinguish trees with the same number of joins)
        ##  - we take the tree with lower total-edge-weight, where edges are weighted by `antiPriority`
        ##  - the job will fail if there is not a single tree with lowest total-edge-weight
        ##
        antiPriority: 1

        ## configs for excluding edges provided by this relationship
        ##
        exclusions:

          - ## a set of data sources, between which, we cut any edges created by this relationship
            ##
            ## WARNING:
            ##  - must contain at least 2 data sources (otherwise, no edges would be cut)
            ##
            dataSourceSet:

              - ## the kind of data source
                ##
                kind: "ComplexVirtualDataSource" ## TODO: remove after test

                ## the name of the data source
                ##
                name: "test" ## TODO: remove after test

              ## TODO: remove after test
              - kind: "SimpleVirtualDataSource"
                name: "test"

    ## the maximum depth of the data model tree before the job will fail
    ##
    ## WARNING:
    ##  - the maximum possible depth of struct types in the output data will be (1 + `maxDepth` + "max depth of your source data")
    ##
    ## NOTE:
    ##  - this can be used as a sanity check, so that we don't produce data which systems like BigQuery can't read
    ##
    maxDepth: 14

  ## configs related to the output folder
  ##
  outputFolder:

    ## the uri of the output folder
    ##
    ## WARNING:
    ##  - this folder must not contain anything on first run
    ##  - the path must end in a '/'
    ##
    ## EXAMPLE:
    ##    folderUri: "gs://my_bucket/xxxxx.aranui/"
    ##
    folderUri: "gs://my_bucket/xxxxx.aranui/" ## TODO: remove after test

    ## the format of the output data
    ##
    ## WARNING:
    ##  - this config cannot change after the first run
    ##
    ## FORMAT:
    ##  - `PARQUET`
    ##  - `AVRO`
    ##  - `JSONL`
    ##
    dataFormat: "PARQUET"

    ## the compression of the output data
    ##
    ## WARNING:
    ##  - this config cannot change after the first run
    ##
    ## FORMAT:
    ##  - `SNAPPY`
    ##  - `NONE`
    ##
    dataCompression: "SNAPPY"

    ## how we work through a snapshot backlog
    ##
    ## FORMAT:
    ##  - `OLDEST_FIRST`
    ##  - `NEWEST_FIRST`
    ##
    snapshotCatchupMode: "OLDEST_FIRST"

    ## how snapshots are physically stored in the output
    ##
    ## WARNING:
    ##  - exactly one option must be specified, the rest must be excluded
    ##
    snapshotFormat:

      ## where snapshots are stored using using 'hive-like' folder partitioning
      ##
      hivePartitioned:

        ## the name of the snapshot partition field
        ##
        ## WARNING:
        ##  - must must be unique within this OutputDataset
        ##
        fieldName: "snapshot_epoch"

        ## the timestamp format to store the snapshot in
        ##
        ## FORMAT:
        ##  - `ISO8601_DATE_TIME`: a string with ISO8601 date-time format (ex: '2020-01-01T00:00:00Z')
        ##  - `UNIX_MILLISECONDS`: a long with unix epoch in milliseconds
        ##  - `UNIX_SECONDS`:      a long with unix epoch in seconds
        ##
        timestampFormat: "UNIX_MILLISECONDS"

        ## the timezone to write the snapshot in ("tz database" format)
        ##
        ## EXAMPLE:
        ##    timezone: "America/New_York"
        ##
        ## NOTE:
        ##  - currently only applicable to `ISO8601_DATE_TIME`
        ##
        outputTimezone: "UTC"

    ## configs for automatically deleting snapshots
    ##
    snapshotAutoDelete:

      ## automatically delete output snapshots for times older than this
      ##
      ## NOTE:
      ##  - after each new snapshot is appended, the app will delete the oldest snapshot until
      ##    this condition is met
      ##  - the latest snapshot will NEVER be deleted by this check
      ##
      maxSnapshotAge:
        nano: 0
        second: 0
        minute: 0
        hour: 0
        day: 0
        week: 0
        month: 0
        year: 0

      ## automatically delete output snapshots which were created more than this time ago
      ##
      ## NOTE:
      ##  - after each new snapshot is appended, the app will delete the oldest snapshot until
      ##    this condition is met
      ##  - the latest snapshot will NEVER be deleted by this check
      ##  - this can be used to give a 'grace period' for jobs to finish reading tables
      ##    (for tables where only the latest snapshot matters, like transaction-events)
      ##
      maxSnapshotCreationAge:
        nano: 0
        second: 0
        minute: 0
        hour: 0
        day: 0
        week: 0
        month: 0
        year: 0

      ## the maximum number of old snapshots
      ##
      ## NOTE:
      ##  - after each new snapshot is appended, the app will delete the oldest snapshot until
      ##    this condition is met
      ##  - the latest snapshot will NEVER be deleted by this check
      ##
      ## FORMAT:
      ##  - `-1`: keep all
      ##  - `0`:  keep latest only
      ##  - `+N:` keep latest + N
      ##
      maxOldSnapshots: -1

